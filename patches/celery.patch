--- a/billiard/pool.py
+++ b/billiard/pool.py
@@ -1741,8 +1741,8 @@ class ApplyResult:
         cache[self._job] = self
 
     def __repr__(self):
-        return '<%s: {id} ack:{ack} ready:{ready}>'.format(
-            self.__class__.__name__,
+        return '<{name}: {id} ack:{ack} ready:{ready}>'.format(
+            name=self.__class__.__name__,
             id=self._job, ack=self._accepted, ready=self.ready(),
         )
 
--- a/billiard/process.py
+++ b/billiard/process.py
@@ -144,7 +144,7 @@ class BaseProcess:
         res = self._popen.wait(timeout)
         if res is not None:
             _children.discard(self)
-        self.close()
+            self.close()
 
     def is_alive(self):
         '''
--- a/celery/app/task.py
+++ b/celery/app/task.py
@@ -788,6 +788,7 @@ class Task:
 
         request = {
             'id': task_id,
+            'task': self.name,
             'retries': retries,
             'is_eager': True,
             'logfile': logfile,
@@ -824,7 +825,7 @@ class Task:
         if isinstance(retval, Retry) and retval.sig is not None:
             return retval.sig.apply(retries=retries + 1)
         state = states.SUCCESS if ret.info is None else ret.info.state
-        return EagerResult(task_id, retval, state, traceback=tb)
+        return EagerResult(task_id, self.name, retval, state, traceback=tb)
 
     def AsyncResult(self, task_id, **kwargs):
         """Get AsyncResult instance for the specified task.
--- a/celery/app/trace.py
+++ b/celery/app/trace.py
@@ -250,8 +250,8 @@ class TraceInfo:
             safe_repr(eobj),
             safe_str(einfo.traceback),
             einfo.exc_info,
-            safe_repr(req.args),
-            safe_repr(req.kwargs),
+            req.get('argsrepr') or safe_repr(req.args),
+            req.get('kwargsrepr') or safe_repr(req.kwargs),
         )
         policy = get_log_policy(task, einfo, eobj)
 
@@ -559,8 +559,8 @@ def build_tracer(
                                 'name': get_task_name(task_request, name),
                                 'return_value': Rstr,
                                 'runtime': T,
-                                'args': safe_repr(args),
-                                'kwargs': safe_repr(kwargs),
+                                'args': task_request.get('argsrepr') or safe_repr(args),
+                                'kwargs': task_request.get('kwargsrepr') or safe_repr(kwargs),
                             })
 
                 # -* POST *-
--- a/celery/backends/database/models.py
+++ b/celery/backends/database/models.py
@@ -25,6 +25,7 @@ class Task(ResultModelBase):
     date_done = sa.Column(sa.DateTime, default=datetime.utcnow,
                           onupdate=datetime.utcnow, nullable=True)
     traceback = sa.Column(sa.Text, nullable=True)
+    children = sa.Column(PickleType, nullable=True)
 
     def __init__(self, task_id):
         self.task_id = task_id
@@ -36,6 +37,7 @@ class Task(ResultModelBase):
             'result': self.result,
             'traceback': self.traceback,
             'date_done': self.date_done,
+            'children': self.children,
         }
 
     def __repr__(self):
--- a/celery/beat.py
+++ b/celery/beat.py
@@ -282,7 +282,10 @@ class Scheduler:
             error('Message Error: %s\n%s',
                   exc, traceback.format_stack(), exc_info=True)
         else:
-            debug('%s sent. id->%s', entry.task, result.id)
+            if result and hasattr(result, 'id'):
+                debug('%s sent. id->%s', entry.task, result.id)
+            else:
+                debug('%s sent.', entry.task)
 
     def adjust(self, n, drift=-0.010):
         if n and n > 0:
--- a/celery/bin/celery.py
+++ b/celery/bin/celery.py
@@ -173,7 +173,7 @@ def celery(ctx, app, broker, result_backend, loader, config, workdir,
 
 @celery.command(cls=CeleryCommand)
 @click.pass_context
-def report(ctx):
+def report(ctx, **kwargs):
     """Shows information useful to include in bug-reports."""
     app = ctx.obj.app
     app.loader.import_default_modules()
--- a/celery/bin/multi.py
+++ b/celery/bin/multi.py
@@ -469,7 +469,7 @@ class MultiTool(TermLogger):
 )
 @click.pass_context
 @handle_preload_options
-def multi(ctx):
+def multi(ctx, **kwargs):
     """Start multiple worker instances."""
     cmd = MultiTool(quiet=ctx.obj.quiet, no_color=ctx.obj.no_color)
     # In 4.x, celery multi ignores the global --app option.
--- a/celery/bin/purge.py
+++ b/celery/bin/purge.py
@@ -5,7 +5,9 @@ from celery.bin.base import COMMA_SEPARATED_LIST, CeleryCommand, CeleryOption, h
 from celery.utils import text
 
 
-@click.command(cls=CeleryCommand)
+@click.command(cls=CeleryCommand, context_settings={
+    'allow_extra_args': True
+})
 @click.option('-f',
               '--force',
               cls=CeleryOption,
@@ -26,7 +28,7 @@ from celery.utils import text
               help="Comma separated list of queues names not to purge.")
 @click.pass_context
 @handle_preload_options
-def purge(ctx, force, queues, exclude_queues):
+def purge(ctx, force, queues, exclude_queues, **kwargs):
     """Erase all messages from all known task queues.
 
     Warning:
--- a/celery/bin/shell.py
+++ b/celery/bin/shell.py
@@ -79,7 +79,9 @@ def _invoke_default_shell(locals):
         _invoke_ipython_shell(locals)
 
 
-@click.command(cls=CeleryCommand)
+@click.command(cls=CeleryCommand, context_settings={
+    'allow_extra_args': True
+})
 @click.option('-I',
               '--ipython',
               is_flag=True,
@@ -117,7 +119,7 @@ def _invoke_default_shell(locals):
 @handle_preload_options
 def shell(ctx, ipython=False, bpython=False,
           python=False, without_tasks=False, eventlet=False,
-          gevent=False):
+          gevent=False, **kwargs):
     """Start shell session with convenient access to celery symbols.
 
     The following symbols will be added to the main globals:
--- a/celery/canvas.py
+++ b/celery/canvas.py
@@ -1672,7 +1672,7 @@ class group(Signature):
         #
         # We return a concretised tuple of the signatures actually applied to
         # each child task signature, of which there might be none!
-        return tuple(child_task.link_error(sig) for child_task in self.tasks)
+        return tuple(child_task.link_error(sig.clone(immutable=True)) for child_task in self.tasks)
 
     def _prepared(self, tasks, partial_args, group_id, root_id, app,
                   CallableSignature=abstract.CallableSignature,
@@ -1704,7 +1704,7 @@ class group(Signature):
             generator: A generator for the unrolled group tasks.
                 The generator yields tuples of the form ``(task, AsyncResult, group_id)``.
         """
-        for task in tasks:
+        for index, task in enumerate(tasks):
             if isinstance(task, CallableSignature):
                 # local sigs are always of type Signature, and we
                 # clone them to make sure we don't modify the originals.
@@ -1721,7 +1721,7 @@ class group(Signature):
             else:
                 if partial_args and not task.immutable:
                     task.args = tuple(partial_args) + tuple(task.args)
-                yield task, task.freeze(group_id=group_id, root_id=root_id), group_id
+                yield task, task.freeze(group_id=group_id, root_id=root_id, group_index=index), group_id
 
     def _apply_tasks(self, tasks, producer=None, app=None, p=None,
                      add_to_parent=None, chord=None,
@@ -2216,9 +2216,6 @@ class _chord(Signature):
         options = dict(self.options, **options) if options else self.options
         if options:
             options.pop('task_id', None)
-            stamped_headers = set(body.options.get("stamped_headers", []))
-            stamped_headers.update(options.get("stamped_headers", []))
-            options["stamped_headers"] = list(stamped_headers)
             body.options.update(options)
 
         bodyres = body.freeze(task_id, root_id=root_id)
@@ -2276,7 +2273,7 @@ class _chord(Signature):
         """
         if self.app.conf.task_allow_error_cb_on_chord_header:
             for task in self.tasks:
-                task.link_error(errback)
+                task.link_error(errback.clone(immutable=True))
         else:
             # Once this warning is removed, the whole method needs to be refactored to:
             # 1. link the error callback to each task in the header
--- a/celery/contrib/testing/manager.py
+++ b/celery/contrib/testing/manager.py
@@ -6,6 +6,7 @@ from functools import partial
 from itertools import count
 from typing import Any, Callable, Dict, Sequence, TextIO, Tuple  # noqa
 
+from kombu.exceptions import ContentDisallowed
 from kombu.utils.functional import retry_over_time
 
 from celery import states
@@ -207,6 +208,24 @@ class ManagerMixin:
             raise Sentinel()
         return res
 
+    def wait_until_idle(self):
+        control = self.app.control
+        with self.app.connection() as connection:
+            while True:
+                count = control.purge(connection=connection)
+                if count == 0:
+                    break
+
+            inspect = control.inspect()
+            inspect.connection = connection
+            while True:
+                try:
+                    count = sum(len(t) for t in inspect.active().values())
+                except ContentDisallowed:
+                    break
+                if count == 0:
+                    break
+
 
 class Manager(ManagerMixin):
     """Test helpers for task integration tests."""
--- a/celery/contrib/testing/worker.py
+++ b/celery/contrib/testing/worker.py
@@ -1,4 +1,5 @@
 """Embedded workers for integration tests."""
+import logging
 import os
 import threading
 from contextlib import contextmanager
@@ -29,11 +30,45 @@ test_worker_stopped = Signal(
 class TestWorkController(worker.WorkController):
     """Worker that can synchronize on being fully started."""
 
+    logger_queue = None
+
     def __init__(self, *args, **kwargs):
         # type: (*Any, **Any) -> None
         self._on_started = threading.Event()
+
         super().__init__(*args, **kwargs)
 
+        if self.pool_cls.__module__.split('.')[-1] == 'prefork':
+            from billiard import Queue
+            self.logger_queue = Queue()
+            self.pid = os.getpid()
+
+            try:
+                from tblib import pickling_support
+                pickling_support.install()
+            except ImportError:
+                pass
+
+            self.queue_listener = logging.handlers.QueueListener(self.logger_queue, logging.getLogger())
+            self.queue_listener.start()
+
+    class QueueHandler(logging.handlers.QueueHandler):
+        def prepare(self, record):
+            record.from_queue = True
+            return record
+
+        def handleError(self, record):
+            if logging.raiseExceptions:
+                raise
+
+    def start(self):
+        if self.logger_queue:
+            handler = self.QueueHandler(self.logger_queue)
+            handler.addFilter(lambda r: r.process != self.pid and not getattr(r, 'from_queue', False))
+            logger = logging.getLogger()
+            logger.addHandler(handler)
+        return super().start()
+
     def on_consumer_ready(self, consumer):
         # type: (celery.worker.consumer.Consumer) -> None
         """Callback called when the Consumer blueprint is fully started."""
--- a/celery/result.py
+++ b/celery/result.py
@@ -980,10 +980,11 @@ class GroupResult(ResultSet):
 class EagerResult(AsyncResult):
     """Result that we know has already been executed."""
 
-    def __init__(self, id, ret_value, state, traceback=None):
+    def __init__(self, id, name, ret_value, state, traceback=None):
         # pylint: disable=super-init-not-called
         # XXX should really not be inheriting from AsyncResult
         self.id = id
+        self._name = name
         self._result = ret_value
         self._state = state
         self._traceback = traceback
@@ -1035,6 +1036,7 @@ class EagerResult(AsyncResult):
     @property
     def _cache(self):
         return {
+            'name': self._name,
             'task_id': self.id,
             'result': self._result,
             'status': self._state,
--- a/celery/utils/term.py
+++ b/celery/utils/term.py
@@ -168,7 +168,7 @@ def supports_images():
 def _read_as_base64(path):
     with codecs.open(path, mode='rb') as fh:
         encoded = base64.b64encode(fh.read())
-        return encoded if type(encoded) == 'str' else encoded.decode('ascii')
+        return encoded if isinstance(encoded, str) else encoded.decode('ascii')
 
 
 def imgcat(path, inline=1, preserve_aspect_ratio=0, **kwargs):
--- a/celery/worker/consumer/consumer.py
+++ b/celery/worker/consumer/consumer.py
@@ -153,6 +153,8 @@ class Consumer:
 
     restart_count = -1  # first start is the same as a restart
 
+    first_connection_attempt = True
+
     class Blueprint(bootsteps.Blueprint):
         """Consumer blueprint."""
 
@@ -337,7 +339,8 @@ class Consumer:
             except recoverable_errors as exc:
                 # If we're not retrying connections, we need to properly shutdown or terminate
                 # the Celery main process instead of abruptly aborting the process without any cleanup.
-                is_connection_loss_on_startup = self.restart_count == 0
+                is_connection_loss_on_startup = self.first_connection_attempt
+                self.first_connection_attempt = False
                 connection_retry_type = self._get_connection_retry_type(is_connection_loss_on_startup)
                 connection_retry = self.app.conf[connection_retry_type]
                 if not connection_retry:
@@ -494,7 +497,11 @@ class Consumer:
         # TODO: Rely only on broker_connection_retry_on_startup to determine whether connection retries are disabled.
         #       We will make the switch in Celery 6.0.
 
+        retry_disabled = False
+
         if self.app.conf.broker_connection_retry_on_startup is None:
+            retry_disabled = not self.app.conf.broker_connection_retry
+
             warnings.warn(
                 CPendingDeprecationWarning(
                     f"The broker_connection_retry configuration setting will no longer determine\n"
@@ -502,16 +509,23 @@ class Consumer:
                     f"If you wish to retain the existing behavior for retrying connections on startup,\n"
                     f"you should set broker_connection_retry_on_startup to {self.app.conf.broker_connection_retry}.")
             )
+        else:
+            if self.first_connection_attempt:
+                retry_disabled = not self.app.conf.broker_connection_retry_on_startup
+            else:
+                retry_disabled = not self.app.conf.broker_connection_retry
 
-        if not self.app.conf.broker_connection_retry and not self.app.conf.broker_connection_retry_on_startup:
+        if retry_disabled:
             # Retry disabled, just call connect directly.
             conn.connect()
+            self.first_connection_attempt = False
             return conn
 
         conn = conn.ensure_connection(
             _error_handler, self.app.conf.broker_connection_max_retries,
             callback=maybe_shutdown,
         )
+        self.first_connection_attempt = False
         return conn
 
     def _flush_events(self):
--- a/celery/worker/strategy.py
+++ b/celery/worker/strategy.py
@@ -2,7 +2,6 @@
 import logging
 
 from kombu.asynchronous.timer import to_timestamp
-from kombu.utils.encoding import safe_repr
 
 from celery import signals
 from celery.app import trace as _app_trace
@@ -155,8 +154,9 @@ def default(task, app, consumer,
             context = {
                 'id': req.id,
                 'name': req.name,
-                'args': safe_repr(req.args),
-                'kwargs': safe_repr(req.kwargs),
+                'args': req.argsrepr,
+                'kwargs': req.kwargsrepr,
+                'eta': req.eta,
             }
             info(_app_trace.LOG_RECEIVED, context, extra={'data': context})
         if (req.expires or req.id in revoked_tasks) and req.revoked():
--- a/kombu/connection.py
+++ b/kombu/connection.py
@@ -543,12 +543,6 @@ class Connection:
         """
         if retry_errors is None:
             retry_errors = tuple()
-        elif max_retries is None:
-            # If the retry_errors is specified, but max_retries is not,
-            # this could lead into an infinite loop potentially.
-            raise ValueError(
-                "max_retries must be specified if retry_errors is specified"
-            )
 
         def _ensured(*args, **kwargs):
             got_connection = 0
--- a/kombu/transport/redis.py
+++ b/kombu/transport/redis.py
@@ -1079,6 +1079,11 @@ class Channel(virtual.Channel):
 
     def close(self):
         self._closing = True
+        if self._in_poll:
+            try:
+                self._brpop_read()
+            except Empty:
+                pass
         if not self.closed:
             # remove from channel poller.
             self.connection.cycle.discard(self)
--- a/kombu/utils/objects.py
+++ b/kombu/utils/objects.py
@@ -5,13 +5,12 @@ from __future__ import annotations
 __all__ = ('cached_property',)
 
 try:
-    from functools import _NOT_FOUND
     from functools import cached_property as _cached_property
 except ImportError:
     # TODO: Remove this fallback once we drop support for Python < 3.8
     from cached_property import threaded_cached_property as _cached_property
 
-    _NOT_FOUND = object()
+_NOT_FOUND = object()
 
 
 class cached_property(_cached_property):
--- a/vine/__init__.py
+++ b/vine/__init__.py
@@ -1,16 +1,19 @@
 """Promises, promises, promises."""
 import re
-
 from collections import namedtuple
 
 from .abstract import Thenable
-from .promises import promise
-from .synchronization import barrier
 from .funtools import (
-    maybe_promise, ensure_promise,
-    ppartial, preplace, starpromise, transform, wrap,
+    ensure_promise,
+    maybe_promise,
+    ppartial,
+    preplace,
+    starpromise,
+    transform,
+    wrap,
 )
-
+from .promises import promise
+from .synchronization import barrier
 
 __version__ = '5.0.0'
 __author__ = 'Ask Solem'
@@ -29,8 +32,8 @@ _temp = re.match(
     r'(\d+)\.(\d+).(\d+)(.+)?', __version__).groups()
 VERSION = version_info = version_info_t(
     int(_temp[0]), int(_temp[1]), int(_temp[2]), _temp[3] or '', '')
-del(_temp)
-del(re)
+del (_temp)
+del (re)
 
 __all__ = [
     'Thenable', 'promise', 'barrier',
--- a/vine/promises.py
+++ b/vine/promises.py
@@ -1,9 +1,8 @@
 """Promise implementation."""
+import inspect
 import sys
-
 from collections import deque
-import inspect
-from weakref import ref, WeakMethod
+from weakref import WeakMethod, ref
 
 from .abstract import Thenable
 from .utils import reraise
@@ -78,6 +77,7 @@ class promise:
             'fun', 'args', 'kwargs', 'ready', 'failed',
             'value', 'ignore_result', 'reason', '_svpending', '_lvpending',
             'on_error', 'cancelled', 'weak', '__weakref__',
+            "__dict__",
         )
 
     def __init__(self, fun=None, args=None, kwargs=None,
--- a/vine/synchronization.py
+++ b/vine/synchronization.py
@@ -57,6 +57,13 @@ class barrier:
         if callback:
             self.then(callback)
 
+        __slots__ = (
+            'p', 'args', 'kwargs', '_value', 'size',
+            'ready', 'reason', 'cancelled', 'finalized',
+            '__weakref__',
+            "__dict__",
+        )
+
     def __call__(self, *args, **kwargs):
         if not self.ready and not self.cancelled:
             self._value += 1
--- a/vine/utils.py
+++ b/vine/utils.py
@@ -1,9 +1,6 @@
 """Python compatibility utilities."""
-from functools import (
-    WRAPPER_ASSIGNMENTS, WRAPPER_UPDATES,
-    update_wrapper as _update_wrapper,
-    partial,
-)
+from functools import WRAPPER_ASSIGNMENTS, WRAPPER_UPDATES, partial
+from functools import update_wrapper as _update_wrapper
 
 __all__ = ['update_wrapper', 'wraps']
 
